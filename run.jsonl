{"id":"run_1702600000000","experimentId":"exp_transformer_ablation","title":"Self-Attention Head Ablation Study","status":"completed","startDate":"2024-01-20T14:00:00Z","endDate":"2024-01-22T18:30:00Z","codeUrl":"experiments/transformer_ablation_001/run/train.py","dataPath":"data/wmt14_en_de_preprocessed/","hyperparameters":{"model":"transformer_base","num_heads":[1,2,4,8,16],"d_model":512,"num_layers":6,"learning_rate":0.0001,"batch_size":32,"max_epochs":50},"metrics":{"final_bleu":[18.2,22.5,26.8,27.1,27.0],"training_time_hours":[12.5,13.2,14.8,16.3,18.1]},"notes":"Ablation study showing diminishing returns beyond 8 attention heads. 4-8 heads appears to be the sweet spot for this model size.","createdDate":"2024-01-20T13:00:00Z"}